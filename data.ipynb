{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data has been converted to JSON and saved to 'companies.json'.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Paths to the input CSV and output JSON files\n",
    "csv_file_path = 'Companies ranked by Market Cap.csv'\n",
    "json_file_path = 'companies.json'\n",
    "\n",
    "# List to store the JSON records\n",
    "json_data = []\n",
    "\n",
    "# Mapping of CSV columns to JSON fields\n",
    "csv_to_json_map = {\n",
    "    \"Name\": \"name\",\n",
    "    \"marketcap\": \"marketcap\",\n",
    "    \"country\": \"country\",\n",
    "    \"Symbol\": \"symbol\"\n",
    "}\n",
    "\n",
    "# Function to read the CSV and convert to JSON\n",
    "def convert_csv_to_json():\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            json_record = {json_field: row[csv_field] for csv_field, json_field in csv_to_json_map.items()}\n",
    "            # Add the JSON record to the list\n",
    "            json_data.append(json_record)\n",
    "\n",
    "    # Write the JSON data to a file\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"CSV data has been converted to JSON and saved to '{json_file_path}'.\")\n",
    "\n",
    "# Run the conversion function\n",
    "convert_csv_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded logo for AAPL\n",
      "Downloaded logo for MSFT\n",
      "Downloaded logo for NVDA\n",
      "Downloaded logo for GOOG\n",
      "Downloaded logo for AMZN\n",
      "Downloaded logo for 2222.SR\n",
      "Downloaded logo for META\n",
      "Downloaded logo for BRK-B\n",
      "Downloaded logo for TSM\n",
      "Downloaded logo for LLY\n",
      "Downloaded logo for AVGO\n",
      "Downloaded logo for TSLA\n",
      "Downloaded logo for JPM\n",
      "Downloaded logo for NVO\n",
      "Downloaded logo for WMT\n",
      "Downloaded logo for UNH\n",
      "Downloaded logo for XOM\n",
      "Downloaded logo for V\n",
      "Downloaded logo for TCEHY\n",
      "Downloaded logo for MA\n",
      "Downloaded logo for PG\n",
      "Downloaded logo for 005930.KS\n",
      "Downloaded logo for COST\n",
      "Downloaded logo for JNJ\n",
      "Downloaded logo for ORCL\n",
      "Downloaded logo for MC.PA\n",
      "Downloaded logo for ASML\n",
      "Downloaded logo for HD\n",
      "Downloaded logo for ABBV\n",
      "Downloaded logo for BAC\n",
      "Downloaded logo for KO\n",
      "Downloaded logo for NFLX\n",
      "Downloaded logo for MRK\n",
      "Downloaded logo for 1398.HK\n",
      "Downloaded logo for CVX\n",
      "Downloaded logo for NESN.SW\n",
      "Downloaded logo for AZN\n",
      "Downloaded logo for ROG.SW\n",
      "Downloaded logo for CRM\n",
      "Downloaded logo for SAP\n",
      "Downloaded logo for 600519.SS\n",
      "Downloaded logo for TM\n",
      "Downloaded logo for ADBE\n",
      "Downloaded logo for RMS.PA\n",
      "Downloaded logo for IHC.AE\n",
      "Downloaded logo for AMD\n",
      "Downloaded logo for RELIANCE.NS\n",
      "Downloaded logo for PEP\n",
      "Downloaded logo for NVS\n",
      "Downloaded logo for TMO\n",
      "Downloaded logo for TMUS\n",
      "Downloaded logo for OR.PA\n",
      "Downloaded logo for 601288.SS\n",
      "Downloaded logo for SHEL\n",
      "Downloaded logo for 601857.SS\n",
      "Downloaded logo for LIN\n",
      "Downloaded logo for PDD\n",
      "Downloaded logo for 0941.HK\n",
      "Downloaded logo for ACN\n",
      "Downloaded logo for FMX\n",
      "Downloaded logo for MCD\n",
      "Downloaded logo for CSCO\n",
      "Downloaded logo for BABA\n",
      "Downloaded logo for DHR\n",
      "Downloaded logo for ABT\n",
      "Downloaded logo for QCOM\n",
      "Downloaded logo for TCS.NS\n",
      "Downloaded logo for WFC\n",
      "Downloaded logo for 601939.SS\n",
      "Downloaded logo for GE\n",
      "Downloaded logo for PM\n",
      "Downloaded logo for INTU\n",
      "Downloaded logo for TXN\n",
      "Downloaded logo for IBM\n",
      "Downloaded logo for 601988.SS\n",
      "Downloaded logo for AXP\n",
      "Downloaded logo for AMGN\n",
      "Downloaded logo for AMAT\n",
      "Downloaded logo for NOW\n",
      "Downloaded logo for VZ\n",
      "Downloaded logo for ISRG\n",
      "Downloaded logo for CAT\n",
      "Downloaded logo for MS\n",
      "Downloaded logo for DIS\n",
      "Downloaded logo for NEE\n",
      "Downloaded logo for PFE\n",
      "Downloaded logo for IDEXY\n",
      "Downloaded logo for PRX.AS\n",
      "Downloaded logo for GS\n",
      "Downloaded logo for RY\n",
      "Downloaded logo for TTE\n",
      "Downloaded logo for HSBC\n",
      "Downloaded logo for RTX\n",
      "Downloaded logo for CMCSA\n",
      "Downloaded logo for SPGI\n",
      "Downloaded logo for CBA.AX\n",
      "Downloaded logo for HDB\n",
      "Downloaded logo for UL\n",
      "Downloaded logo for UBER\n",
      "Downloaded logo for UNP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Create a directory to save the logos\n",
    "os.makedirs('company_logos', exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "company_symbols = [symbol for symbol in df['Symbol'].head(100)]\n",
    "\n",
    "\n",
    "# Base URL for the logos\n",
    "base_url = 'https://companiesmarketcap.com/img/company-logos/64/'\n",
    "\n",
    "def download_logos():\n",
    "    for symbol in company_symbols:\n",
    "        logo_url = f\"{base_url}{symbol}.webp\"\n",
    "        response = requests.get(logo_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            logo_filename = os.path.join('company_logos', f\"{symbol}.webp\")\n",
    "            with open(logo_filename, 'wb') as logo_file:\n",
    "                logo_file.write(response.content)\n",
    "            print(f\"Downloaded logo for {symbol}\")\n",
    "        else:\n",
    "            print(f\"Failed to download logo for {symbol}: Status code {response.status_code}\")\n",
    "\n",
    "download_logos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated JSON file saved as 'top_100_companies_with_symbols.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Paths to the files\n",
    "json_file_path = 'top_100_companies.json'\n",
    "csv_file_path = 'Companies ranked by Market Cap.csv'\n",
    "output_json_file_path = 'top_100_companies_with_symbols.json'\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    companies_json = json.load(json_file)\n",
    "\n",
    "# Load the CSV data\n",
    "symbol_map = {}\n",
    "with open(csv_file_path, 'r') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    for row in reader:\n",
    "        company_name = row['Name']\n",
    "        symbol = row['Symbol']\n",
    "        symbol_map[company_name] = symbol\n",
    "\n",
    "# Add symbols to the JSON data\n",
    "for company in companies_json:\n",
    "    company_name = company['name']\n",
    "    company['symbol'] = symbol_map.get(company_name, \"UNKNOWN\")\n",
    "\n",
    "# Save the updated JSON data\n",
    "with open(output_json_file_path, 'w') as output_json_file:\n",
    "    json.dump(companies_json, output_json_file, indent=4)\n",
    "\n",
    "print(f\"Updated JSON file saved as '{output_json_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'AI50 2024.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# Function to get latitude and longitude\n",
    "def get_lat_lon(location):\n",
    "    try:\n",
    "        loc = geolocator.geocode(location)\n",
    "        if loc:\n",
    "            return loc.latitude, loc.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to the 'HEADQUARTERS' column\n",
    "data[['Latitude', 'Longitude']] = data['HEADQUARTERS'].apply(lambda x: pd.Series(get_lat_lon(x)))\n",
    "\n",
    "# Display the updated dataset with Latitude and Longitude\n",
    "data.head()\n",
    "data.to_csv(\"AI50-w-geodata.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'rank' has been removed and saved to 'top1002004_clean.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def delete_field_from_json(input_file, output_file, field_to_delete):\n",
    "    # Load JSON data from the input file\n",
    "    with open(input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Check if the data is a list of objects\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            if field_to_delete in item:\n",
    "                del item[field_to_delete]\n",
    "    else:\n",
    "        print(\"Expected a list of JSON objects in the input file.\")\n",
    "\n",
    "    # Save the modified data to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "    print(f\"Field '{field_to_delete}' has been removed and saved to '{output_file}'.\")\n",
    "\n",
    "# Example usage\n",
    "input_file = 'top1002004.json'\n",
    "output_file = 'top1002004_clean.json'\n",
    "field_to_delete = 'rank'  # Example field to delete\n",
    "\n",
    "delete_field_from_json(input_file, output_file, field_to_delete)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
